# üìù Publications

A full publication list is available on my [google scholar](https://scholar.google.com.hk/citations?user=NB9Mn5MAAAAJ&hl=zh-CN) page.

<!-- Paper 1 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/TransFace.png' alt="sym" width="90%"></div></div>
<div class='paper-box-text' markdown="1">

[**ICCV 2023**] [TransFace: Calibrating Transformer Training for Face Recognition from a Data-Centric Perspective](https://openaccess.thecvf.com/content/ICCV2023/html/Dan_TransFace_Calibrating_Transformer_Training_for_Face_Recognition_from_a_Data-Centric_ICCV_2023_paper.html) \\
**Jun Dan**, Yang Liu, Haoyu Xie, Jiankang Deng, Haoran Xie, Xuansong Xie, Baigui Sun
[![GitHub Stars](https://img.shields.io/github/stars/DanJun6737/TransFace?style=social)](https://github.com/DanJun6737/TransFace)
[![GitHub Forks](https://img.shields.io/github/forks/DanJun6737/TransFace?style=social)](https://github.com/DanJun6737/TransFace)
[[**ModelScope**]](https://www.modelscope.cn/models/iic/cv_vit_face-recognition)
[[Code in FaceChain Rep.]](https://github.com/modelscope/facechain/tree/main/face_module/TransFace)
[[ÈòøÈáå‰∫ë]](https://developer.aliyun.com/article/1319924)
[[CSDN]](https://blog.csdn.net/sunbaigui/article/details/136556006)

- TopoFR is the first attempt to leverage the powerful and substantial structure information hidden in large-scale face dataset to improve the generalization performance of face recognition models.
- TransFace model has reached over **15K+** downloads on the [**ModelScope**](https://www.modelscope.cn/models/iic/cv_vit_face-recognition) platform, and has been applied in various facial AIGC projects, such as [Alibaba Tongyi Wanxiang (ÈÄö‰πâ‰∏áË±°ÂÜôÁúüÈ¶Ü)](https://tongyi.aliyun.com/wanxiang/), [FaceChain](https://github.com/modelscope/facechain), Fliggy (È£ûÁå™Êï∞Â≠óÊóÖÊãç) and so on.



</div>
</div>


<!-- Paper 2 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024 </div><img src='images/TopoFR.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**NeurIPS 2024**] [TopoFR: A Closer Look at Topology Alignment on Face Recognition](https://proceedings.neurips.cc/paper_files/paper/2024/hash/419b6c974712adb884bfbbeea8e94d1b-Abstract-Conference.html) \\
**Jun Dan**, Yang Liu, Jiankang Deng, Haoyu Xie, Siyuan Li, Baigui Sun, Shan Luo
[![GitHub Stars](https://img.shields.io/github/stars/modelscope/facechain?style=social)](https://github.com/modelscope/facechain)
[![GitHub Forks](https://img.shields.io/github/forks/modelscope/facechain?style=social)](https://github.com/modelscope/facechain)
<a href='https://huggingface.co/spaces/developer0hye/TopoFR-Face-Recognition'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Demo-blue'></a>
[[Êú∫Âô®‰πãÂøÉ]](https://www.jiqizhixin.com/articles/2024-10-17-6) 
[[CVer]](https://mp.weixin.qq.com/s/3NegnpJUGPfI_dOfkp_4LQ) 
[[CSDN]](https://blog.csdn.net/sunbaigui/article/details/143230746?spm=1001.2014.3001.5502)

- TopoFR is the first attempt to leverage the powerful and substantial structure information hidden in large-scale face dataset to improve the generalization performance of face recognition models.
- TopoFR achieves SOTA performance on various face benchmarks.


</div>
</div>


<!-- Paper 2 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024 </div><img src='images/papers/2-InstructVideo-CVPR24.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**CVPR 2024**] [InstructVideo: Instructing Video Diffusion Models with Human Feedback](https://arxiv.org/abs/2312.12490)  \\
H. Yuan, S. Zhang, X. Wang, Y. Wei, T. Feng, **Yining Pan**, Y. Zhang, Z. Liu, S. Albanie, D. Ni \\
[![GitHub Stars](https://img.shields.io/github/stars/damo-vilab/i2vgen-xl?style=social)](https://github.com/damo-vilab/i2vgen-xl)
[![GitHub Forks](https://img.shields.io/github/forks/damo-vilab/i2vgen-xl?style=social)](https://github.com/damo-vilab/i2vgen-xl)
[[Project page]](https://instructvideo.github.io/)

- InstructVideo is the first research attempt that instructs video diffusion models with human feedback.
- InstructVideo significantly enhances the visual quality of generated videos without compromising generalization capabilities, with merely 0.1% of the parameters being fine-tuned.

</div>
</div>

<!-- Paper 3 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023 </div><img src='images/papers/1-RLIPv2-ICCV23.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**ICCV 2023**] [RLIPv2: Fast Scaling of Relational Language-Image Pre-training](https://arxiv.org/abs/2308.09351) \\
H. Yuan, S. Zhang, X. Wang, S. Albanie, **Yining Pan**, T. Feng, J. Jiang, D. Ni, Y. Zhang, D. Zhao \\
[![GitHub Stars](https://img.shields.io/github/stars/JacobYuan7/RLIPv2?style=social)](https://github.com/JacobYuan7/RLIPv2)
[![GitHub Forks](https://img.shields.io/github/forks/JacobYuan7/RLIPv2?style=social)](https://github.com/JacobYuan7/RLIPv2)

- RLIPv2 elevates [RLIP](https://arxiv.org/abs/2209.01814) by leveraging a new language-image fusion mechanism, designed for expansive data scales.

</div>
</div>
